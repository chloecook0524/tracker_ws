#!/usr/bin/env python3
# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import uuid
import json
import math
import traceback
from collections import deque

# íƒ€ì… íŒíŠ¸
from typing import List, Dict

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from shapely.geometry import Polygon
from pyquaternion import Quaternion
from scipy.optimize import linear_sum_assignment
from lap import lapjv

# ROS ê´€ë ¨
import rospy
import tf
import tf.transformations
from std_msgs.msg import Header, Float32
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Point

# ë©”ì‹œì§€ ì •ì˜ (ì»¤ìŠ¤í…€ í¬í•¨)
from lidar_processing_msgs.msg import LidarPerceptionOutput, LidarObject
from lidar_processing_msgs.msg import PfGMFATrack, PfGMFATrackArray
from vdcl_fusion_perception.msg import DetectionObjects
from chassis_msgs.msg import Chassis
from collections import defaultdict

# === BBox í´ë˜ìŠ¤ (bbox.py ë‚´ìš© í†µí•©) ===
class BBox:
    def __init__(self, frame_id, bbox, **kwargs):
        self.frame_id = frame_id
        self.is_fake = False
        self.is_interpolation = False
        self.category = bbox["category"]
        self.det_score = bbox["detection_score"]
        self.lwh = bbox["lwh"]
        self.global_xyz = bbox["global_xyz"]
        self.global_orientation = bbox["global_orientation"]
        self.global_yaw = bbox["global_yaw"]
        self.global_velocity = bbox["global_velocity"]
        self.global_acceleration = bbox["global_acceleration"]

        # ì´ˆê¸° ìƒíƒœë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ fusion/predictìš©ìœ¼ë¡œ ì‚¬ìš©
        self.global_velocity_fusion = self.global_velocity
        self.global_acceleration_fusion = self.global_acceleration
        self.global_yaw_fusion = self.global_yaw
        self.lwh_fusion = self.lwh

        # ì†ë„ ë³€í™” ì¶”ì • (ë‹¨ìˆœ ì´ˆê¸°í™”)
        self.global_velocity_diff = [0, 0]
        self.global_velocity_curve = [0, 0]

        # ìœ„ì¹˜ + í¬ê¸° + ê°ë„ í†µí•© í‘œí˜„
        self.global_xyz_lwh_yaw = self.global_xyz + list(self.lwh) + [self.global_yaw]

        # ê³¼ê±° ìœ„ì¹˜ ì¶”ì • (ë³´ê°„ ê°€ëŠ¥)
        self.global_xyz_last = self.backward_prediction()
        self.global_xyz_lwh_yaw_last = self.global_xyz_last + list(self.lwh) + [self.global_yaw]

        self.global_xyz_lwh_yaw_predict = self.global_xyz_lwh_yaw
        self.global_xyz_lwh_yaw_fusion = self.global_xyz_lwh_yaw
        self.unmatch_length = 0

    def backward_prediction(self):
        last_xy = np.array(self.global_xyz[:2]) - np.array(self.global_velocity) * 0.5
        return last_xy.tolist() + [self.global_xyz[2]]
    

    def transform_3dbox2corners(self, global_xyz_lwh_yaw) -> np.ndarray:
        from pyquaternion import Quaternion  # ensure imported

        x, y, z, l, w, h, rot = global_xyz_lwh_yaw
        orientation = Quaternion(axis=[0, 0, 1], radians=rot)
        dx1, dx2, dy1, dy2, dz1, dz2 = (
            l / 2.0,
            l / 2.0,
            w / 2.0,
            w / 2.0,
            h / 2.0,
            h / 2.0,
        )
        x_corners = np.array([dx1, dx1, dx1, dx1, dx2, dx2, dx2, dx2]) * np.array(
            [1, 1, 1, 1, -1, -1, -1, -1]
        )
        y_corners = np.array([dy1, dy2, dy2, dy1, dy1, dy2, dy2, dy1]) * np.array(
            [1, -1, -1, 1, 1, -1, -1, 1]
        )
        z_corners = np.array([dz1, dz1, dz2, dz2, dz1, dz1, dz2, dz2]) * np.array(
            [1, 1, -1, -1, 1, 1, -1, -1]
        )
        corners = np.vstack((x_corners, y_corners, z_corners))
        corners = np.dot(orientation.rotation_matrix, corners)
        corners[0, :] += x
        corners[1, :] += y
        corners[2, :] += z
        return corners.T   


def cal_rotation_iou_inbev(pose1, pose2):
    import cv2
    box1 = np.array([pose1[0], pose1[1], pose1[3], pose1[4], pose1[6] * 180 / np.pi])
    box2 = np.array([pose2[0], pose2[1], pose2[3], pose2[4], pose2[6] * 180 / np.pi])
    base_xy = np.array(box1[:2])
    box1[:2] -= base_xy
    box2[:2] -= base_xy
    area1 = pose1[3] * pose1[4]
    area2 = pose2[3] * pose2[4]
    box1_inp = ((box1[0], box1[1]), (box1[2], box1[3]), box1[4])
    box2_inp = ((box2[0], box2[1]), (box2[2], box2[3]), box2[4])

    int_pts = cv2.rotatedRectangleIntersection(tuple(box1_inp), tuple(box2_inp))[1]
    if int_pts is not None:
        order_pts = cv2.convexHull(int_pts, returnPoints=True)
        union = cv2.contourArea(order_pts)
        iou = union / (area1 + area2 - union)
    else:
        iou = 0.0
        union = 0.0
    return iou, union

def get_class_weights(class_id):
    """
    í´ë˜ìŠ¤ë³„ Hybrid Cost ê³„ì‚° ì‹œ ì‚¬ìš©í•˜ëŠ” GDIoU ì¤‘ì‹¬ ê°€ì¤‘ì¹˜
    - ë°˜í™˜ê°’: (area_penalty_weight, center_dist_weight)
    """
    weights = {
        1: (0.5, 1.5),  # car
        2: (1.0, 1.0),  # truck
        3: (0.6, 0.4),  # bus
        4: (1.0, 1.0),  # trailer
        6: (1.0, 1.0),  # pedestrian
        7: (1.0, 1.0),  # motorcycle
        8: (1.0, 1.0),  # bicycle
        # í•„ìš” ì‹œ ë‹¤ë¥¸ í´ë˜ìŠ¤ ì¶”ê°€
    }
    return weights.get(class_id, (0.7, 0.3))  # default weight

def get_confidence_weights(class_id):
    """
    í´ë˜ìŠ¤ë³„ confidence blending ê°€ì¤‘ì¹˜
    - ë°˜í™˜ê°’: (det_score_weight, pred_score_weight)
    """
    weights = {
        1:  (0.5, 0.5),  # car
        2:  (0.5, 0.5),  # truck
        3:  (0.5, 0.5),  # bus
        4:  (0.6, 0.4),  # trailer
        5:  (0.6, 0.4),  # construction vehicle
        6:  (0.6, 0.4),  # pedestrian
        7:  (0.5, 0.5),  # motorcycle
        8:  (0.6, 0.4),  # bicycle
        9:  (0.8, 0.2),  # barrier
        10: (0.8, 0.2),  # traffic cone
    }
    return weights.get(class_id, (0.5, 0.5))

# === Utility Functions ===

def orientation_similarity(angle1_rad, angle2_rad):
    cosine_similarity = math.cos((angle1_rad - angle2_rad + np.pi) % (2 * np.pi) - np.pi)
    return (cosine_similarity + 1.0) / 2.0

def create_ego_marker(stamp):
    marker = Marker()
    marker.header.frame_id = "vehicle"
    marker.header.stamp = stamp
    marker.ns = "ego_vehicle"
    marker.id = 9999
    marker.type = Marker.MESH_RESOURCE
    marker.action = Marker.ADD
    marker.mesh_resource = "package://vdcl_fusion_perception/marker_dae/Car.dae"
    marker.mesh_use_embedded_materials = True

    marker.pose.position.x = 1.5
    marker.pose.position.y = 0.0
    marker.pose.position.z = 0.0

    quaternion = Quaternion(axis=[0, 0, 1], angle=0)
    marker.pose.orientation.w = quaternion[0]
    marker.pose.orientation.x = quaternion[1]
    marker.pose.orientation.y = quaternion[2]
    marker.pose.orientation.z = quaternion[3]

    marker.scale.x = 4.0
    marker.scale.y = 2.0
    marker.scale.z = 2.0

    marker.color.a = 1.0
    marker.color.r = 0.0
    marker.color.g = 1.0
    marker.color.b = 0.0
    marker.lifetime = rospy.Duration(0.2)

    return marker

    
def create_single_track_marker(track, header, marker_id):
    m = Marker()
    m.header = header
    m.ns = "track_meshes"
    m.id = marker_id
    m.action = Marker.ADD
    m.type = Marker.MESH_RESOURCE
    m.mesh_use_embedded_materials = True
    m.pose.position.x = track["x"] 
    m.pose.position.y = track["y"]
    
    # âœ… Z ìœ„ì¹˜ ë³´ì • (ì¤‘ì‹¬ ê¸°ì¤€)
    z_base = track["position"][2]
    m.pose.position.z = z_base

    
    q = tf.transformations.quaternion_from_euler(0, 0, track["yaw"])
    m.pose.orientation.x = q[0]
    m.pose.orientation.y = q[1]
    m.pose.orientation.z = q[2]
    m.pose.orientation.w = q[3]

    m.scale.x = track["size"][0]
    m.scale.y = track["size"][1]
    m.scale.z = track["size"][2]

    m.color.a = min(track["confidence"] * 5, 1.0)
    m.lifetime = rospy.Duration(0.0)
    m.color.r = 0.0
    m.color.g = 0.2
    m.color.b = 1.0

    class_mesh_paths = {
        1: "package://vdcl_fusion_perception/marker_dae/Car.dae",
        2: "package://vdcl_fusion_perception/marker_dae/Truck.dae",
        3: "package://vdcl_fusion_perception/marker_dae/Bus.dae",
        4: "package://vdcl_fusion_perception/marker_dae/Trailer.dae",
        5: "package://vdcl_fusion_perception/marker_dae/Truck.dae",
        6: "package://vdcl_fusion_perception/marker_dae/Pedestrian.dae",
        7: "package://vdcl_fusion_perception/marker_dae/Motorcycle.dae",
        8: "package://vdcl_fusion_perception/marker_dae/Bicycle.dae",
        9: "package://vdcl_fusion_perception/marker_dae/Barrier.dae",
        10: "package://vdcl_fusion_perception/marker_dae/TrafficCone.dae",
    }
    m.mesh_resource = class_mesh_paths.get(track["type"], "")
    return m

def create_text_marker(track, header, marker_id):
    # # ğŸ¯ íŠ¹ì • í´ë˜ìŠ¤ëŠ” ID ë§ˆì»¤ ìƒëµ
    # if track["type"] in [9, 10]:  # 9: barrier, 10: traffic cone
    #     return None
    t_m = Marker()
    t_m.header = header
    t_m.ns = "track_ids"
    t_m.id = marker_id
    t_m.type = Marker.TEXT_VIEW_FACING
    t_m.action = Marker.ADD
    t_m.pose.position.x = track["x"]
    t_m.pose.position.y = track["y"]
    t_m.pose.position.z = track["position"][2] + track["size"][2] + 2.5 if "position" in track and len(track["position"]) > 2 else track["size"][2] + 1.0
    t_m.scale.z = 0.8
    t_m.color.a = 1.0
    t_m.color.r = 1.0
    t_m.color.g = 1.0
    t_m.color.b = 1.0
    t_m.text = str(track["id"])
    return t_m

def create_arrow_marker(track, header, marker_id):
    vx, vy = track.get("velocity", [0.0, 0.0])
    speed = math.hypot(vx, vy)

    arrow = Marker()
    arrow.header = header
    arrow.ns = "track_arrows"
    arrow.id = marker_id
    arrow.type = Marker.ARROW
    arrow.action = Marker.ADD
    arrow.scale.x = 0.2
    arrow.scale.y = 0.5
    arrow.scale.z = 0.3
    arrow.color.r = 1.0
    arrow.color.g = 1.0
    arrow.color.b = 1.0

    STATIC_CLASSES = {9, 10}  # barrier, traffic cone
    if track["type"] in STATIC_CLASSES:
        arrow.color.a = 0.0
    else:
        arrow.color.a = 1.0 if speed > 0.1 else 0.0

    z_base = track["position"][2]
    z_center = z_base + track["size"][2] / 2.0

    arrow.points.append(Point(x=track["x"], y=track["y"], z=z_center))
    arrow.points.append(Point(x=track["x"] + vx, y=track["y"] + vy, z=z_center))

    return arrow

def cal_rotation_gdiou_inbev(box_trk, box_det, class_id, cal_flag=None):
    if cal_flag == "Predict":
        pose1 = box_trk.bboxes[-1].global_xyz_lwh_yaw_predict
        pose2 = box_det.global_xyz_lwh_yaw
    elif cal_flag == "BackPredict":
        pose1 = box_trk.bboxes[-1].global_xyz_lwh_yaw_fusion
        pose2 = box_det.global_xyz_lwh_yaw_last
    else:
        raise ValueError(f"Unexpected cal_flag value: {cal_flag}")

    corners1 = box_trk.bboxes[-1].transform_3dbox2corners(pose1)
    corners2 = box_det.transform_3dbox2corners(pose2)
    bev_idxes = [2, 3, 7, 6]
    bev_corners1 = corners1[bev_idxes, 0:2]
    bev_corners2 = corners2[bev_idxes, 0:2]
    pose1 = np.copy(pose1)
    pose2 = np.copy(pose2)
    iou, inter_area = cal_rotation_iou_inbev(pose1, pose2)
    union_points = np.concatenate([bev_corners1, bev_corners2], axis=0).astype(np.float64)
    union_points -= pose1[:2].reshape(1, 2)
    rect = cv2.minAreaRect(union_points.astype(np.float32))
    universe_area = rect[1][0] * rect[1][1]
    a_area = pose1[3] * pose1[4]
    b_area = pose2[3] * pose2[4]
    extra_area = universe_area - (a_area + b_area - inter_area)
    box_center_distance = (pose1[0] - pose2[0]) ** 2 + (pose1[1] - pose2[1]) ** 2
    union_distance = np.linalg.norm(np.array(rect[1])) ** 2
    box_trk_volume = pose1[3] * pose1[4] * pose1[5]
    box_det_volume = pose2[3] * pose2[4] * pose2[5]
    volume_ratio = (
        box_trk_volume / box_det_volume if box_trk_volume >= box_det_volume else box_det_volume / box_trk_volume
    )
    angle_ratio = orientation_similarity(pose1[6], pose2[6])
    w1, w2 = get_class_weights(class_id)

    ro_gdiou = (
        iou
        - w1 * extra_area / universe_area
        - w2 * box_center_distance / union_distance
    )
    
    # rospy.loginfo(f"[GDIoU] class={class_id}, IoU={iou:.3f}, "
    #             f"extra_area={extra_area:.3f}, center_dist={box_center_distance:.3f}, "
    #             f"volume_ratio={volume_ratio:.2f}, angle_sim={angle_ratio:.2f}, final={ro_gdiou:.3f}")

    return ro_gdiou


def ro_gdiou_2d(box1, box2, yaw1, yaw2):
    """
    MCTrackì—ì„œ ì‚¬ìš©í•˜ëŠ” yaw-penalized IoU ìœ ì‚¬ í•¨ìˆ˜
    box1, box2: [w, l] (í¬ê¸°)
    yaw1, yaw2: íšŒì „ ê°ë„ (radian)
    """
    w1, l1 = box1
    w2, l2 = box2

    if w1 <= 0 or l1 <= 0 or w2 <= 0 or l2 <= 0:
        return 0.0

    # 1. ì¼ë°˜ IoU ê³„ì‚° (íšŒì „ ë¬´ì‹œ, ì¶• ì •ë ¬ bbox ê°€ì •)
    inter_w = min(w1, w2)
    inter_l = min(l1, l2)
    inter_area = inter_w * inter_l
    union_area = w1 * l1 + w2 * l2 - inter_area
    iou = inter_area / union_area if union_area > 0 else 0.0

    # 2. yaw ì°¨ì´ì— ëŒ€í•œ cosine penalty
    yaw_diff = abs(yaw1 - yaw2)
    yaw_penalty = 1.0 - np.cos(yaw_diff)

    # 3. penalty ì ìš© GDIoU ìœ ì‚¬ ë³´ì •
    ro_gdiou = iou - 0.1 * yaw_penalty
    return max(0.0, ro_gdiou)    

# === Matching Threshold Helpers ===
def _get_class_distance_threshold(label):
    pedestrian_like = [6, 7, 8]
    return 1.5 if label in pedestrian_like else 3.0

def get_confirmed_bonus(label):
    """
    í´ë˜ìŠ¤ë³„ CONFIRMED íŠ¸ë™ì— ëŒ€í•œ cost ë³´ë„ˆìŠ¤ ë¹„ìœ¨ ë°˜í™˜
    ì‘ì„ìˆ˜ë¡ ë” í° ë³´ë„ˆìŠ¤ (ì¦‰, cost í• ì¸í­ í¼)
    """
    if label in [1, 2, 3, 4]:  # ì°¨ëŸ‰ë¥˜
        return 0.7
    elif label in [6, 7, 8]:   # pedestrian, motorcycle, bicycle
        return 0.85
    else:
        return 0.8

# ìœ ì‚¬ í´ë˜ìŠ¤ ê·¸ë£¹ ì •ì˜
SIMILAR_CLASS_GROUPS = [
    {2, 3, 4, 5},  # truck, bus, trailer, construction_vehicle
    {6},     # pedestrian
    {1, 7, 8},           # car, motorcycle, bicycle
    {9, 10},       # barrier, cone
]

def get_class_group(class_id):
    for group in SIMILAR_CLASS_GROUPS:
        if class_id in group:
            return group
    return None

# === Hungarian IoU Matching Function with predicted boxes and distance-based cost ===
def hungarian_iou_matching(tracks, detections, dt=0.1, use_precise_gdiou=False):
    if not tracks or not detections:
        rospy.logwarn("[Hungarian Matching] No tracks or detections available!")
        return [], list(range(len(detections))), list(range(len(tracks))), [], []

    VALID_CLASS_IDS = set(CLASS_CONFIG.keys())
    detections = [d for d in detections if d["type"] in VALID_CLASS_IDS]

    cost_thresholds = {
        1: 1.8,   # car
        2: 2.0,   # truck
        3: 2.0,   # bus
        4: 2.0,   # trailer
        5: 2.0,   # construction_vehicle
        6: 2.0,   # pedestrian
        7: 2.0,   # motorcycle
        8: 2.0,   # bicycle
        9: 1.8,   # barrier
        10: 2.0,  # traffic cone
    }
    default_threshold = 2.2

    cost_matrix = np.ones((len(tracks), len(detections))) * 1e6

    for i, track in enumerate(tracks):
        for j, det in enumerate(detections):
            # === ìœ ì‚¬ í´ë˜ìŠ¤ ê·¸ë£¹ ê¸°ë°˜ penalty ì ìš©
            group_track = get_class_group(track.label)
            group_det = get_class_group(det["type"])

            # âœ… ëª¨ë“  ìƒíƒœì—ì„œ ê·¸ë£¹ì´ ë‹¤ë¥´ë©´ ë¬´ì¡°ê±´ ë§¤ì¹­ ê¸ˆì§€
            if group_track != group_det:
                cost_matrix[i, j] = 1e6
                continue
                    
            if group_track != group_det:
                class_penalty = 1.0  # ê·¸ë£¹ì´ ì™„ì „íˆ ë‹¤ë¥´ë©´ ê°•í•œ penalty
            elif track.label != det["type"]:
                class_penalty = 0.2  # ê°™ì€ ê·¸ë£¹ ë‚´ì—ì„œ classê°€ ë‹¤ë¥´ë©´ ì•½í•œ penalty
            else:
                class_penalty = 0.0  # ì™„ì „íˆ ë™ì¼í•˜ë©´ penalty ì—†ìŒ

            pos_track = track.x[:2]
            pos_det = np.array(det["position"][:2])
            dist = np.linalg.norm(pos_track - pos_det)

            yaw_diff = abs(track.x[3] - det["yaw"])
            yaw_penalty = 1.0 - np.cos(yaw_diff)

            if use_precise_gdiou:
                bbox_det = BBox(
                    frame_id=det.get("id", -1),
                    bbox={
                        "category": det["type"],
                        "detection_score": det.get("confidence", 0.5),
                        "lwh": det["size"],
                        "global_xyz": det["position"],
                        "global_orientation": [0, 0, 0, 1],
                        "global_yaw": det["yaw"],
                        "global_velocity": det.get("velocity", [0.0, 0.0]),
                        "global_acceleration": [0.0, 0.0],
                    }
                )
                ro_iou = cal_rotation_gdiou_inbev(track, bbox_det, class_id=track.label, cal_flag="Predict")
            else:
                ro_iou = ro_gdiou_2d(track.size[:2], det["size"][:2], track.x[3], det["yaw"])
            iou_penalty = 1.0 - max(ro_iou, 0.0)

            if track.label in [6, 7, 8]:  # ì‘ì€ ê°ì²´
                cost = 0.5 * dist + 0.3 * yaw_penalty + 0.2 * iou_penalty
            else:
                cost = 0.4 * dist + 0.3 * yaw_penalty + 0.3 * iou_penalty

            cost += class_penalty  # âœ… í´ë˜ìŠ¤ ì°¨ì´ì— ëŒ€í•œ íŒ¨ë„í‹° ì¶”ê°€

            # if track.label in [6, 7, 8]:
            #     with open("/tmp/mctrack_cost_debug.txt", "a") as f:
            #         f.write(
            #             f"[HYBRID_COST][CLS={track.label}] T#{i} ID={track.id} status={track.status_flag} "
            #             f"traj_len={track.traj_length} missed={track.missed_count} â†’ "
            #             f"dist={dist:.2f}, yaw_diff={yaw_diff:.2f}, ro_gdiou={ro_iou:.3f}, cost={cost:.3f}\n"
            #         )

            if hasattr(track, "status_flag") and track.status_flag == TrackState.CONFIRMED:
                cost *= get_confirmed_bonus(track.label)
            if cost > 10.0:
                continue

            cost_matrix[i, j] = cost

            # âœ… ë¡œê¹…
            # with open("/tmp/mctrack_cost_debug.txt", "a") as f:
            #     f.write(
            #         f"[HYBRID_COST] T#{i} ID={track.id} vs D#{j} "
            #         f"â†’ dist={dist:.2f}, yaw_diff={yaw_diff:.2f}, ro_gdiou={ro_iou:.3f}, cost={cost:.3f}\n"
            #     )

        # === [7] ë””ë²„ê¹… ë¡œê·¸ (ì„ íƒ) ===
        # with open("/tmp/mctrack_cost_debug.txt", "a") as f:
        #     f.write(f"[COST] T#{i} (ID={track.id}) vs D#{j} â†’ dist={dist:.2f}, yaw_diff={yaw_diff:.2f}, cost={cost:.3f}\n")

            # with open("/tmp/mctrack_cost_debug.txt", "a") as f:
            #     f.write(f"[COST] T#{i} (ID={track.id}) vs D#{j} â†’ IoU={iou_score:.3f}, dist={dist:.2f}, cost={cost_matrix[i,j]:.3f}\n")
    
    # === Hungarian Matching with Exception-Safe lapjv + Logging ===
    try:
        res = lapjv(cost_matrix, extend_cost=True, cost_limit=default_threshold)
        if not isinstance(res, tuple) or len(res) != 3:
            rospy.logwarn("[Hungarian] lapjv ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")
            return [], list(range(len(detections))), list(range(len(tracks))), [], []
        total_cost, row_ind, col_ind = res
    except Exception as e:
        rospy.logerr(f"[Hungarian] lapjv failed: {e}")
        return [], list(range(len(detections))), list(range(len(tracks))), [], []

    matches = []
    unmatched_tracks = set(range(len(tracks)))
    unmatched_dets = set(range(len(detections)))

    for i, j in enumerate(row_ind):
        if j == -1 or i >= len(tracks) or j >= len(detections):
            continue
        cost = cost_matrix[i, j]
        label = tracks[i].label
        threshold = cost_thresholds.get(label, default_threshold)

        if cost < threshold:
            matches.append((i, j))
            unmatched_tracks.discard(i)
            unmatched_dets.discard(j)
        # else:
        #     if label in [6, 7, 8]:  # ì†Œí˜• ê°ì²´ë§Œ ë¡œê¹…
        #         log_line = (f"[HUNGARIAN FAIL] CLS={label} T#{i} ID={tracks[i].id} vs D#{j} "
        #                     f"â†’ dist={np.linalg.norm(tracks[i].x[:2] - np.array(detections[j]['position'][:2])):.2f}, "
        #                     f"yaw_diff={abs(tracks[i].x[3] - detections[j]['yaw']):.2f}, "
        #                     f"cost={cost:.3f}, threshold={threshold:.2f}, ro_gdiou={ro_iou:.3f}")
        #         with open("/tmp/mctrack_cost_debug.txt", "a") as f:
        #             f.write(log_line + "\n")

    # for ti in unmatched_tracks:
    #     if ti < len(tracks):
    #         best_di = int(np.argmin(cost_matrix[ti]))
    #         best_cost = float(cost_matrix[ti][best_di])
            # rospy.loginfo(f"[UNMATCHED] T#{ti} vs best D#{best_di}: cost={best_cost:.2f}")
            # with open("/tmp/mctrack_cost_debug.txt", "a") as f:
            #     f.write(f"[UNMATCHED] T#{ti} vs best D#{best_di}: cost={best_cost:.2f}\n")

    matched_tracks = [tracks[i] for i, _ in matches]
    matched_detections = [detections[j] for _, j in matches]

    return matches, list(unmatched_dets), list(unmatched_tracks), matched_tracks, matched_detections

# === TrackState Enum ===
class TrackState:
    INITIALIZATION = 0
    CONFIRMED = 1
    OBSCURED = 2
    DEAD = 3

CLASS_NAME_MAP = {
    1: "car", 6: "pedestrian", 8: "bicycle", 7: "motorcycle", 3: "bus",
    4: "trailer", 2: "truck", 9: "barrier", 10: "cone", 5:"construction_vehicle",
}
# === í´ë˜ìŠ¤ë³„ ì¹¼ë§Œ í•„í„° ì„¤ì • (MCTRACK ì™„ì„± ë²„ì „) ===
CLASS_CONFIG = {
    1: {  # car
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 25,
        'max_predict_time': 2.5, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 10.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.5, 0.5, 1.5, 1.5]),
        'R': np.diag([0.7, 0.7, 0.5, 0.5]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),      # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 0.1,               # ê´€ì¸¡ ì‹ ë¢°ë„ ë†’ì„ â†’ detectionì„ ì ê·¹ ë°˜ì˜
    },
    6: {  # pedestrian
        'confirm_threshold': 2,                 # ê¸°ì¡´ 1
        'max_unmatch': 4,                       # ê¸°ì¡´ 1
        'max_predict_len': 25,                  # ê¸°ì¡´ 7 * 2.8
        'max_predict_time': 2.5, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 1.5,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.5, 0.5, 1.5, 1.5]),
        'R': np.diag([0.7, 0.7, 1.0, 1.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),       # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 0.02,     
    },
    8:  {  # bicycle
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 25,
        'max_predict_time': 2.5, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 7.0,
        'P': np.diag([1.0, 1.0, 1.0, 1.0]),
        'Q': np.diag([0.3, 0.3, 1.0, 1.0]),
        'R': np.diag([0.1, 0.1, 1.0, 1.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),         # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 0.02,     
    },
    7: {  # motorcycle
        'confirm_threshold': 2,
        'max_unmatch': 4,
        'max_predict_len': 30,
        'max_predict_time': 3.0, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 8.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.5, 0.5, 4.0, 4.0]),
        'R': np.diag([0.3, 0.3, 1.0, 1.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),       # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 0.02,     
    },
    3:  {  # bus
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 28,
        'max_predict_time': 2.8, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 6.0,
        'P': np.diag([100.0, 100.0, 100.0, 100.0]),
        'Q': np.diag([0.5, 0.5, 1.5, 1.5]),
        'R': np.diag([1.5, 1.5, 500.0, 500.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),         # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 0.01,                   # ê´€ì¸¡ ì‹ ë¢°ë„ ë†’ì„ â†’ detectionì„ ì ê·¹ ë°˜ì˜
    },
    4: {  # trailer
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 20,
        'max_predict_time': 2.0, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 3.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.3, 0.3, 0.1, 0.1]),
        'R': np.diag([2.0, 2.0, 2.5, 2.5]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),        # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 1.0,               # ê´€ì¸¡ ì‹ ë¢°ë„ ë†’ì„ â†’ detectionì„ ì ê·¹ ë°˜ì˜
    },
    2: {  # truck
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 30,
        'max_predict_time': 3.0, 
        'confirmed_match_score': 0.7,
        'is_filter_predict_box': -1,
        'expected_velocity': 1.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.1, 0.1, 2.0, 2.0]),
        'R': np.diag([1.5, 1.5, 4.0, 4.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),       # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 1.0,               # ê´€ì¸¡ ì‹ ë¢°ë„ ë†’ì„ â†’ detectionì„ ì ê·¹ ë°˜ì˜
    },
    9: {  # barrier
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 15,
        'max_predict_time': 1.5, 
        'confirmed_match_score': 0.5,
        'is_filter_predict_box': -1,
        'expected_velocity': 0.0,  # ì •ì  ê°ì²´ë¡œ ê°€ì •
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.1, 0.1, 0.1, 0.1]),
        'R': np.diag([0.5, 0.5, 10.0, 10.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),         # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 20,               # ê´€ì¸¡ ì‹ ë¢°ë„ ë†’ì„ â†’ detectionì„ ì ê·¹ ë°˜ì˜
    },
    10: {  # traffic cone
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 15,
        'max_predict_time': 1.5, 
        'confirmed_match_score': 0.0,
        'is_filter_predict_box': -1,
        'expected_velocity': 0.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.1, 0.1, 0.1, 0.1]),
        'R': np.diag([0.5, 0.5, 10.0, 10.0]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),        # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 20,     
    },
    5: {  # construction_vehicle
        'confirm_threshold': 2,
        'max_unmatch': 3,
        'max_predict_len': 20,
        'max_predict_time': 2.0, 
        'confirmed_match_score': 0.5,
        'is_filter_predict_box': -1,
        'expected_velocity': 3.0,
        'P': np.diag([1.0, 1.0, 10.0, 10.0]),
        'Q': np.diag([0.5, 0.5, 1.0, 1.0]),
        'R': np.diag([0.7, 0.7, 0.5, 0.5]),
        'P_size': np.eye(3),
        'Q_size': np.eye(3),
        'R_size': np.eye(2),
        'P_yaw': np.array([[0.1]]),      # âœ… ë°˜ë“œì‹œ 1x1
        'Q_yaw': np.array([[0.1]]),        # yaw, yaw_rate ì¡ìŒ ì ë‹¹íˆ ë°˜ì˜ (ì˜ˆ: 10Hz ê¸°ì¤€)
        'R_yaw_scalar': 1.0,     
    }
}

# === KalmanTrackedObject (1/2) ===
class KalmanTrackedObject:
    def __init__(self, detection, obj_id=None):
        self.id = obj_id or (uuid.uuid4().int & 0xFFFF)
        self.label = detection['type']
        wlh = detection.get('size', [1.0, 1.0, 1.0])
        self.traj_length = 1
        self.status_flag = TrackState.INITIALIZATION 
        self.hits = 1
        self.yaw_drift_buffer = deque(maxlen=5)
        self.yaw_dir_buffer = deque(maxlen=5)
        px, py = detection['position'][:2]
        vx, vy = detection.get("velocity", [0.0, 0.0])
        self.pose_state = np.array([px, py, vx, vy])
        self.confidence = 0.0
        self.time_since_update = 0.0
        self.class_votes = defaultdict(float)
        self.class_vote_history = deque(maxlen=10)
        self.current_class = detection['type']

        class_cfg = CLASS_CONFIG.get(self.label)
        if class_cfg is not None:
            self.pose_P = class_cfg["P"]
            self.pose_Q = class_cfg["Q"]
            self.pose_R = class_cfg["R"]
            self.size_P = class_cfg["P_size"]
            self.size_Q = class_cfg["Q_size"]
            self.size_R = class_cfg["R_size"]
            self.yaw_P = class_cfg["P_yaw"]# â† 1x1ë¡œ ê³ ì •
            self.yaw_Q = class_cfg["Q_yaw"]# 
            self.R_yaw_scalar = class_cfg["R_yaw_scalar"]
            self.expected_velocity = class_cfg["expected_velocity"]
            self.confirm_threshold = class_cfg["confirm_threshold"]
            self.max_missed = class_cfg["max_unmatch"]
        else:
            self.pose_P = np.diag([1.0, 1.0, 10.0, 10.0])
            self.pose_Q = np.diag([0.5, 0.5, 1.5, 1.5])
            self.pose_R = np.diag([0.7, 0.7, 1.0, 1.0]) 
            self.size_P = np.diag([1.0, 1.0, 1.0])
            self.size_Q = np.diag([0.1, 0.1, 0.1])
            self.size_R = np.diag([0.1, 0.1, 0.1])
            self.yaw_P = np.array([[0.1]])  # â† fallbackë„ 1x1
            self.yaw_Q = np.array([[0.1]])
            self.R_yaw_scalar = 5.0
            self.expected_velocity = 5.0
            self.confirm_threshold = 2
            self.max_missed = 3

        yaw = detection['yaw']
        self.yaw_state = np.array([yaw])  # â† 1ì°¨ì› yaw ìƒíƒœë¡œ ì´ˆê¸°í™”
        self.size_state = np.array(wlh[:3])
        self.age = 0.0
        self.missed_count = 0
        self.bboxes = []

    def predict(self, dt):
        # === Kalman Prediction (pose, velocity) ===
        F = np.eye(4)
        F[0, 2] = dt
        F[1, 3] = dt
        self.pose_state = F @ self.pose_state

        # âœ… ê°ì‡  ì ìš© (velocity damping)
        self.pose_state[2:] *= 0.9  # vx, vy ê°ì‡ ìœ¨ íŠœë‹ ê°€ëŠ¥

        self.pose_P = F @ self.pose_P @ F.T + self.pose_Q

        # === Kalman Prediction (yaw) ===
        # âœ… yawëŠ” ë” ì´ìƒ ì˜ˆì¸¡ ì•ˆ í•¨ â†’ ê³µë¶„ì‚°ë§Œ ì¦ê°€
        self.yaw_P += self.yaw_Q * dt

        # âœ… yaw ê°’ ìœ ì§€ + wrap to [-Ï€, Ï€]
        self.yaw_state[0] = np.arctan2(np.sin(self.yaw_state[0]), np.cos(self.yaw_state[0]))

        # === Kalman Prediction (size) ===
        self.size_P = self.size_P + self.size_Q

        self.age += dt
        self.time_since_update += dt
        self.confidence = self.tracking_score()


        pred_dict = {
            "frame_id": -1,
            "category": self.label,
            "detection_score": self.confidence,
            "lwh": self.size.tolist(),
            "global_xyz": self.pose_state[:2].tolist() + [self.bboxes[-1].global_xyz[2] if self.bboxes else 0.0],
            "global_orientation": [0, 0, 0, 1],
            "global_yaw": self.yaw_state[0],
            "global_velocity": self.pose_state[2:].tolist(),
            "global_acceleration": [0.0, 0.0],
        }

        pred_bbox = BBox(frame_id=pred_dict["frame_id"], bbox=pred_dict)
        pred_bbox.is_fake = True
        self.bboxes.append(pred_bbox)
        if len(self.bboxes) > 30:
            self.bboxes.pop(0)

        if self.status_flag == TrackState.CONFIRMED and self.missed_count > self.max_missed:
            # with open("/tmp/mctrack_cost_debug.txt", "a") as f:
            #     f.write(f"[STATE_CHANGE] ID={self.id} CONFIRMED â†’ OBSCURED | missed={self.missed_count}, max={self.max_missed}\n")
            self.status_flag = TrackState.OBSCURED

        if self.status_flag == TrackState.OBSCURED and self.missed_count > (
            self.max_missed + CLASS_CONFIG[self.label]["max_predict_len"]
        ):
            # === í´ë˜ìŠ¤ ì„¤ì • ê¸°ë°˜ ì‚­ì œ ìœ ì˜ˆ ë²”ìœ„ ê³„ì‚° ===
            base_time = CLASS_CONFIG[self.label].get("max_predict_time", 2.5)
            max_extension = min(base_time * 1.5, 3.0)  # ìµœëŒ€ 3ì´ˆê¹Œì§€ë§Œ ë³´ë¥˜
            threshold = base_time + max_extension

            if self.traj_length > 10 and getattr(self, 'confidence', 0.5) > 0.6 and self.time_since_update < threshold:
                return

            self.status_flag = TrackState.DEAD

    def update(self, detection, dt):
        pos = detection['position']

        # === Kalman Position Update ===
        z = np.array(pos[:2])
        H = np.eye(2, 4)
        y = z - H @ self.pose_state
        S = H @ self.pose_P @ H.T + self.pose_R[:2, :2]
        K = self.pose_P @ H.T @ np.linalg.inv(S)
        self.pose_state += K @ y
        self.pose_P = (np.eye(4) - K @ H) @ self.pose_P

        # === Velocity Blending + Zero Clamp ===
        detect_vel = np.array(detection.get("velocity", [0.0, 0.0]))
        detect_yaw = detection["yaw"]
        speed = np.linalg.norm(detect_vel)

        def normalize_angle(rad):
            return (rad + np.pi) % (2 * np.pi) - np.pi

        if speed > 0.1:
            vel_dir = np.arctan2(detect_vel[1], detect_vel[0])
            vel_dir = normalize_angle(vel_dir)
            yaw_diff_vel = normalize_angle(vel_dir - detect_yaw)
            if abs(yaw_diff_vel) < np.radians(60):
                alpha = 0.5
                self.pose_state[2:4] = (1 - alpha) * self.pose_state[2:4] + alpha * detect_vel
        else:
            # âœ… ë””í…ì…˜ ì†ë„ê°€ 0ì´ë©´ Kalman ì†ë„ë„ êº¼ì¤Œ
            self.pose_state[2:4] = np.zeros(2)
        # === Yaw Drift Buffer ê¸°ë°˜ ì•ˆì •í™” ===
        z_yaw = normalize_angle(detection["yaw"])
        est_yaw = normalize_angle(self.yaw_state[0])
        yaw_diff = normalize_angle(z_yaw - est_yaw)
        speed_est = np.linalg.norm(self.pose_state[2:4])

        # âœ… ì†ë„ì— ë”°ë¼ yaw gateë¥¼ ë¶€ë“œëŸ½ê²Œ ì™„í™” (ì˜ˆ: sigmoid ìŠ¤ì¼€ì¼)
        def compute_yaw_gate(speed_est):
            min_gate = np.radians(90)
            max_gate = np.radians(170)
            k = 0.8   # ìŠ¤ì¼€ì¼ íŒ©í„°
            s = 1 / (1 + np.exp(-k * (speed_est - 2.0)))  # speed_est=2.0 ì¼ ë•Œ ì¤‘ê°„ê°’
            return min_gate + (max_gate - min_gate) * s

        yaw_gate_threshold = compute_yaw_gate(speed_est)

        if abs(yaw_diff) > yaw_gate_threshold:
            if detection.get("confidence", 1.0) < 0.5:
                # rospy.logwarn(f"[YawReject:LowConf] ID={self.id} yaw skipped.")
                return
            elif speed_est < 1.0:
                # rospy.logwarn(f"[YawReject:LowSpeed] ID={self.id} yaw skipped.")
                return

        # âœ… Drift Buffer ëˆ„ì  (í¬ê¸° ê¸°ë°˜)
        self.yaw_drift_buffer.append(yaw_diff)
        if len(self.yaw_drift_buffer) == self.yaw_drift_buffer.maxlen:
            mean_drift = np.mean(self.yaw_drift_buffer)
            drift_mag = abs(mean_drift)

            if drift_mag > np.radians(20):
                # rospy.logwarn(f"[YawDrift] ID={self.id} large drift â†’ force overwrite")
                self.yaw_state[0] = z_yaw
                self.yaw_P = np.eye(1) * 0.05
                self.yaw_drift_buffer.clear()
                self.yaw_dir_buffer.clear()
                return

        # âœ… ì¶”ê°€: ë°©í–¥ ë²¡í„° ë²„í¼ ëˆ„ì 
        yaw_vec = np.array([np.cos(z_yaw), np.sin(z_yaw)])
        est_vec = np.array([np.cos(est_yaw), np.sin(est_yaw)])
        self.yaw_dir_buffer.append(yaw_vec)

        # ë°©í–¥ ë²¡í„° í‰ê· 
        avg_vec = np.mean(self.yaw_dir_buffer, axis=0)
        avg_vec /= np.linalg.norm(avg_vec) + 1e-8

        dot = np.dot(avg_vec, est_vec)

        # rospy.loginfo(f"[YawDir] ID={self.id} dot={dot:.3f}")

        if dot < -0.8 and len(self.yaw_dir_buffer) == self.yaw_dir_buffer.maxlen:
            # rospy.logwarn(f"[YawDirFlip] ID={self.id} persistent flip â†’ force overwrite")
            self.yaw_state[0] = z_yaw
            self.yaw_P = np.eye(1) * 0.05
            self.yaw_dir_buffer.clear()
            self.yaw_drift_buffer.clear()
            return

        # === Yaw Kalman Update ===
        H = np.array([[1.0]])
        R = self.R_yaw_scalar
        S = H @ self.yaw_P @ H.T + R
        K = self.yaw_P @ H.T / S

        deg = lambda rad: rad * 180.0 / np.pi

        # rospy.loginfo(
        #     f"[YawUpdate] ID={self.id} detection={deg(z_yaw):.1f}Â°, "
        #     f"est={deg(est_yaw):.1f}Â°, diff={deg(yaw_diff):.1f}Â°, "
        #     f"K={K[0][0]:.3f}, update={deg(K[0][0] * yaw_diff):.1f}Â°"
        # )

        self.yaw_state[0] += (K * yaw_diff).item()
        self.yaw_state[0] = normalize_angle(self.yaw_state[0])
        self.yaw_P = (np.eye(1) - K @ H) @ self.yaw_P


        # # âœ… Yaw ë®ì–´ì“°ê¸° (ê°„ë‹¨í™”)
        # self.yaw_state[0] = detection['yaw']
        # self.yaw_state[1] = 0.0
        # self.yaw_P = np.eye(2) * 1e-2

        # # === Yaw ì œí•œ ë³´ì • with íŠ ëˆ„ì  ë³´ì™„ + ì†ë„ ê¸°ë°˜ ì™„í™” ===
        # def normalize_angle(angle):
        #     return (angle + np.pi) % (2 * np.pi) - np.pi

        # yaw_det = detection['yaw']
        # prev_yaw = self.yaw_state[0]
        # dt = max(dt, 1e-3)

        # # 1ï¸âƒ£ ê¸°ë³¸ yaw ì°¨ì´
        # yaw_diff = normalize_angle(yaw_det - prev_yaw)
        # yaw_rate = abs(yaw_diff) / dt
        # max_yaw_rate = np.radians(90)

        # # 2ï¸âƒ£ ë“œë¦¬í”„íŠ¸ ë²„í¼ ê´€ë¦¬ (ì¡°ê±´ê³¼ ë¬´ê´€í•˜ê²Œ í•­ìƒ ëˆ„ì )
        # self.yaw_drift_buffer.append(yaw_diff)
        # if len(self.yaw_drift_buffer) > 5:
        #     self.yaw_drift_buffer.popleft()

        # mean_drift = np.mean(self.yaw_drift_buffer)
        # v = np.linalg.norm(self.pose_state[2:4])
        # yaw_drift = abs(mean_drift)

        # # 3ï¸âƒ£ ë³´ì • ê³„ìˆ˜
        # if v < 0.3:
        #     coeff = 0.0
        # elif v < 2.0:
        #     coeff = 0.2
        # else:
        #     coeff = 0.4

        # # 4ï¸âƒ£ ê°•ì œ íŠ ì œê±°: rate ë„ˆë¬´ í¬ë©´ ì„ì‹œ ë¬´ì‹œ (ë‹¨ìˆœ skip ì•„ë‹˜!)
        # if yaw_rate > max_yaw_rate and yaw_drift < np.radians(45):
        #     rospy.logwarn(f"[YawFilter] Unrealistic yaw flip â†’ skip (Î”{np.degrees(yaw_diff):.1f}Â°)")
        #     return  # â›” ë„ˆë¬´ íŠ„ ê±°ë©´ ì´ë²ˆ í”„ë ˆì„ ì—…ë°ì´íŠ¸ skip (ë‹¤ìŒ í”„ë ˆì„ ê¸°ë‹¤ë¦¼)

        # # 5ï¸âƒ£ ë³´ì • ë°©ì‹ ê²°ì •
        # if yaw_drift > np.radians(15):
        #     self.yaw_state[0] = yaw_det
        #     self.yaw_state[1] = 0.0
        #     self.yaw_P = np.eye(2) * 1e-2
        #     self.yaw_drift_buffer.clear()

        # elif abs(mean_drift) < 0.5:
        #     self.yaw_state[0] += coeff * mean_drift
        #     self.yaw_state[0] = normalize_angle(self.yaw_state[0])
        #     self.yaw_state[1] = 0.0
        #     self.yaw_P = np.eye(2) * 1e-2

        # elif (
        #     len(self.yaw_drift_buffer) == 5 and
        #     all(abs(d) > 0.3 for d in self.yaw_drift_buffer) and
        #     np.sign(self.yaw_drift_buffer[0]) == np.sign(self.yaw_drift_buffer[-1])
        # ):
        #     # fallback: ì§€ì†ì ìœ¼ë¡œ í•œ ë°©í–¥ìœ¼ë¡œ drift â†’ ê°•ì œ yaw ìˆ˜ìš©
        #     rospy.logwarn(f"[YawCorrection] Consistent yaw drift â†’ override to detection")
        #     self.yaw_state[0] = yaw_det
        #     self.yaw_state[1] = 0.0
        #     self.yaw_P = np.eye(2) * 1e-2
        #     self.yaw_drift_buffer.clear()

        # # Yaw Kalman Update (ì•ˆì •í™” ë²„ì „)
        # z_yaw = detection["yaw"]
        # yaw_diff = np.arctan2(np.sin(z_yaw - self.yaw_state[0]), np.cos(z_yaw - self.yaw_state[0]))

        # if abs(yaw_diff) > 1.5:
        #     # ê¸‰ê²©í•œ ë³€í™” â†’ ë®ì–´ì“°ê¸°
        #     self.yaw_state[0] = z_yaw
        #     self.yaw_state[1] = 0.0
        #     self.yaw_P = np.eye(2) * 1e-2
        # else:
        #     # ì •ìƒ í•„í„° ì—…ë°ì´íŠ¸
        #     H_yaw = np.array([[1, 0]])
        #     y = np.array([yaw_diff])
        #     R_yaw_scalar = 0.3
        #     Q_yaw = np.diag([0.005, 0.05])
        #     S = H_yaw @ self.yaw_P @ H_yaw.T + R_yaw_scalar
        #     K = self.yaw_P @ H_yaw.T / S
        #     self.yaw_state = self.yaw_state + (K.flatten() * y).flatten()
        #     self.yaw_state[0] = np.arctan2(np.sin(self.yaw_state[0]), np.cos(self.yaw_state[0]))
        #     self.yaw_state[1] = 0.0  # ì•ˆì •í™”ë¥¼ ìœ„í•´ yaw_rateëŠ” ë¬´ì‹œ
        #     self.yaw_P = (np.eye(2) - K @ H_yaw) @ self.yaw_P + Q_yaw

        # # âœ… Size ë®ì–´ì“°ê¸°
        # self.size_state[:2] = detection['size'][:2]
        # self.size_P = np.eye(3) * 1e-2

        # âœ… Size Kalman update (x, y, zì— ëŒ€í•´ ê´€ì¸¡ê°’ ì ìš©)
        # z_size = np.array(detection['size'][:2]) 
        # H_size = np.eye(2, 3) 
        # y_size = z_size - H_size @ self.size_state
        # S_size = H_size @ self.size_P @ H_size.T + self.size_R  # now (2x2)
        # K_size = self.size_P @ H_size.T @ np.linalg.inv(S_size)
        # self.size_state = self.size_state + K_size @ y_size
        # self.size_P = (np.eye(3) - K_size @ H_size) @ self.size_P + self.size_Q

        # === size blending update ===
        det_size = np.array(detection['size'][:2])
        alpha = 0.3
        self.size_state[:2] = (1 - alpha) * self.size_state[:2] + alpha * det_size

        # Optional: height ì—…ë°ì´íŠ¸
        if len(detection['size']) == 3:
            self.size_state[2] = (1 - alpha) * self.size_state[2] + alpha * detection['size'][2]

        # âœ… ê¸°íƒ€ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.missed_count = 0
        self.hits += 1
        self.time_since_update = 0.0
        self.traj_length += 1
        det_score = detection.get("confidence", 0.5)
        pred_score = self.tracking_score()

        alpha, beta = get_confidence_weights(self.label)
        self.confidence = alpha * det_score + beta * pred_score

        if self.traj_length > self.confirm_threshold or self.confidence > CLASS_CONFIG[self.label]["confirmed_match_score"]:
            self.status_flag = TrackState.CONFIRMED

        new_bbox = BBox(frame_id=detection.get("id", 0), bbox={
            "category": self.label,
            "detection_score": self.confidence,
            "lwh": detection["size"],
            "global_xyz": detection["position"][:3],
            "global_orientation": [0, 0, 0, 1],
            "global_yaw": detection["yaw"],
            "global_velocity": detection.get("velocity", [0.0, 0.0]),
            "global_acceleration": [0.0, 0.0],
        })
        self.bboxes.append(new_bbox)
        if len(self.bboxes) > 30:
            self.bboxes.pop(0)

        # === í´ë˜ìŠ¤ íˆ¬í‘œ ê¸°ë°˜ current_class ê°±ì‹  (ì‹¬í”Œ ë²„ì „) ===
        det_cls = detection['type']
        self.class_vote_history.append(det_cls)

        # ìµœëŒ€ ê¸¸ì´ ìœ ì§€
        if len(self.class_vote_history) > 10:
            self.class_vote_history.popleft()

        # ìµœë¹ˆê°’ ê³„ì‚°
        vote_counts = {}
        for c in self.class_vote_history:
            vote_counts[c] = vote_counts.get(c, 0) + 1

        most_common = max(vote_counts.items(), key=lambda x: x[1])[0]

        if most_common != self.label:
            # rospy.loginfo(f"[ClassChange] ID={self.id} {self.label} â†’ {most_common}")
            self.label = most_common
            self.current_class = most_common
            
    def tracking_score(self):
        vel = np.hypot(self.pose_state[2], self.pose_state[3])
        expected_vel = self.expected_velocity
        vel_consistency = np.exp(-abs(vel - expected_vel) / (expected_vel + 1e-3))
        
        traj_penalty = np.exp(-0.2 * self.traj_length)  # trajectory ê¸¸ì´ penalty
        age_bonus = min(1.0, 0.1 * self.age)            # age 10ì´ˆ ì´ìƒì´ë©´ 1.0ìœ¼ë¡œ saturate

        score = (self.hits / (self.age + 1e-3)) * vel_consistency * (1.0 - traj_penalty) * age_bonus
        return max(0.1, min(1.0, score))

    def apply_ego_compensation(self, dx, dy, dyaw):
        cos_yaw = np.cos(-dyaw)
        sin_yaw = np.sin(-dyaw)

        rel_x = self.pose_state[0]
        rel_y = self.pose_state[1]

        self.pose_state[0] = cos_yaw * rel_x - sin_yaw * rel_y - dx
        self.pose_state[1] = sin_yaw * rel_x + cos_yaw * rel_y - dy
        self.yaw_state[0] -= dyaw
        self.yaw_state[0] = np.arctan2(np.sin(self.yaw_state[0]), np.cos(self.yaw_state[0]))

    @property
    def x(self):  # alias for existing usage
        return np.array([
            self.pose_state[0],
            self.pose_state[1],
            np.hypot(self.pose_state[2], self.pose_state[3]),
            self.yaw_state[0],
        ])

    @property
    def size(self):
        return self.size_state    

# === KalmanMultiObjectTracker (predict only) ===
class KalmanMultiObjectTracker:
    def __init__(self, use_precise_gdiou=False):
        self.tracks = []
        self.use_precise_gdiou = use_precise_gdiou 

    def predict(self, dt):
        for t in self.tracks:
            t.predict(dt)
    
    def apply_ego_compensation_to_all(self, dx, dy, dyaw):
        for track in self.tracks:
            track.apply_ego_compensation(dx, dy, dyaw)

    # === Modify Soft-deleted ReID with reproj_bbox filtering ===
    def _recover_obscured_tracks(self, unmatched_dets: List[int], detections: List[Dict], dt: float) -> List[int]:
        used = []

        for di in unmatched_dets:
            det = detections[di]
            label = det['type']

            if label not in CLASS_CONFIG:
                continue

            best_track = None
            best_score = -1e9

            for track in self.tracks:
                if track.label != label:
                    continue
                if track.status_flag != TrackState.OBSCURED:
                    continue
                if track.traj_length > CLASS_CONFIG[label]["max_predict_len"]:
                    continue

                dx = track.pose_state[0] - det["position"][0]
                dy = track.pose_state[1] - det["position"][1]
                dist = np.hypot(dx, dy)
                if dist > _get_class_distance_threshold(label):
                    continue

                # âœ… ì„ íƒì  GDIoU ê³„ì‚° ë°©ì‹
                if self.use_precise_gdiou:
                    bbox_det = BBox(frame_id=det.get("id", -1), bbox={
                        "category": det["type"],
                        "detection_score": det.get("confidence", 0.5),
                        "lwh": det["size"],
                        "global_xyz": det["position"],
                        "global_orientation": [0, 0, 0, 1],
                        "global_yaw": det["yaw"],
                        "global_velocity": det.get("velocity", [0.0, 0.0]),
                        "global_acceleration": [0.0, 0.0],
                    })
                    score = cal_rotation_gdiou_inbev(track, bbox_det, class_id=label, cal_flag="BackPredict")
                else:
                    score = ro_gdiou_2d(track.size[:2], det['size'][:2],
                                        track.yaw_state[0], det['yaw'])

                cost = dist + (1.0 - score)

                if score < 0.5 and cost > 1.5:
                    continue

                if score > best_score:
                    best_score = score
                    best_track = track

            if best_track is not None:
                best_track.status_flag = TrackState.CONFIRMED
                confidence = det.get("confidence", 0.5)

                # âœ… Yaw mismatch ë³´ì • (90ë„ ì´ìƒ ì°¨ì´ ë‚  ê²½ìš°)
                if abs(best_track.yaw_state[0] - det['yaw']) > np.radians(90):
                    # rospy.logwarn(f"[YawInitFix] ReIDëœ íŠ¸ë™ì˜ yawê°€ detectionê³¼ ë„ˆë¬´ ë‹¤ë¦„ â†’ ë®ì–´ì“°ê¸°")
                    best_track.yaw_state[0] = det['yaw']
                    best_track.yaw_P = np.eye(1) * 0.1  # ê³µë¶„ì‚°ë„ ì´ˆê¸°í™”

                best_track.update(det, dt)
                best_track.hits += 1
                used.append(di)

        return used

    def update(self, detections, dt):
        # 0) Predict step for all existing tracks
        for t in self.tracks:
            t.predict(dt)

        unmatched_dets = list(range(len(detections)))
        unmatched_trks = list(range(len(self.tracks)))
        matched_ids = set()

        # 1) Matching using Hungarian algorithm
        if self.tracks and detections:
            _, unmatched_dets, unmatched_trks, matched_trks, matched_dets = \
                hungarian_iou_matching(
                    self.tracks,
                    detections,
                    dt=dt,
                    use_precise_gdiou=self.use_precise_gdiou
                )
            for tr, det in zip(matched_trks, matched_dets):
                tr.update(det, dt)
                matched_ids.add(tr.id)

        # 2) OBSCURED ì²˜ë¦¬: ì§§ì€ íŠ¸ë™ì´ unmatchëœ ê²½ìš°
        for ti in unmatched_trks:
            track = self.tracks[ti]
            if track.traj_length <= 1 and track.missed_count > 0:
                track.status_flag = TrackState.OBSCURED

        # 3~4) ReIDë¡œ OBSCURED íŠ¸ë™ ë³µêµ¬
        used_r = self._recover_obscured_tracks(unmatched_dets, detections, dt)
        unmatched_dets = [d for d in unmatched_dets if d not in used_r]

        # 5) ìƒˆë¡œìš´ íŠ¸ë™ ìƒì„± (í´ë˜ìŠ¤ ë¬´ê´€ ì¤‘ë³µ ì²´í¬)
        for di in unmatched_dets:
            det = detections[di]
            det_label = det["type"]
            is_duplicate = False   # âœ… ê¼­ ì—¬ê¸°ì—ì„œ ì´ˆê¸°í™”í•´ì•¼ í•¨

            for t in self.tracks:
                if t.status_flag not in [TrackState.CONFIRMED, TrackState.OBSCURED]:
                    continue

                group_det = get_class_group(det_label)
                group_trk = get_class_group(t.label)
                if group_det != group_trk:
                    continue

                dist = np.linalg.norm(t.x[:2] - det["position"][:2])
                if dist > 1.5:
                    continue

                score = ro_gdiou_2d(t.size[:2], det["size"][:2], t.x[3], det["yaw"])
                if score > 0.4:
                    # rospy.logwarn(
                    #     f"[Duplicate Suppressed] Det(type={det_label}) near track(id={t.id}, type={t.label}) â†’ dist={dist:.2f}, GDIoU={score:.2f}"
                    # )
                    is_duplicate = True
                    break

            if not is_duplicate:
                self.tracks.append(KalmanTrackedObject(det))

        # 6) ë§¤ì¹­ë˜ì§€ ì•Šì€ íŠ¸ë™ì€ missed_count ì¦ê°€
        for t in self.tracks:
            if t.id not in matched_ids:
                t.missed_count += 1

        # 7) Soft-delete ë° ì‚­ì œ ì¡°ê±´ íŒë‹¨
        MAX_EXTRA_MISSES_FOR_DELETE = 10
        for t in self.tracks:
            if t.status_flag == TrackState.CONFIRMED:
                if t.missed_count > t.max_missed + MAX_EXTRA_MISSES_FOR_DELETE:
                    t.status_flag = TrackState.OBSCURED
            else:
                if t.missed_count > t.max_missed:
                    t.status_flag = TrackState.OBSCURED

        # 9) ì˜¤ë˜ëœ OBSCURED íŠ¸ë™ ì œê±°
        self.tracks = [
            t for t in self.tracks
            if not (t.status_flag == TrackState.OBSCURED and t.time_since_update > 5.0)
        ]

        # ìƒíƒœ ì¶œë ¥
        # rospy.loginfo(f"[Tracker] Total Tracks: {len(self.tracks)}")

    def get_tracks(self):
        results = []

        VALID_LOG_LABELS = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
        filtered_tracks = []

        for t in self.tracks:
            if t.status_flag != TrackState.CONFIRMED:
                continue
            if t.traj_length < 1:
                continue
            if t.label not in VALID_LOG_LABELS:
                continue
            filtered_tracks.append(t)

        # ğŸ”¥ ì¤‘ë³µ ì œê±°: ê°™ì€ ìœ„ì¹˜ì— ë‹¤ë¥¸ class ë‘˜ ì´ìƒ ìˆëŠ” ê²½ìš°
        unique_tracks = []
        for t in filtered_tracks:
            is_duplicate = False
            for u in unique_tracks:
                dist = np.linalg.norm(t.x[:2] - u.x[:2])
                if dist > 1.5:
                    continue
                score = ro_gdiou_2d(t.size[:2], u.size[:2], t.x[3], u.x[3])
                if score > 0.6:
                    # ë‘˜ ì¤‘ confidence ë‚®ì€ ê±¸ ì œê±°
                    if t.confidence < u.confidence:
                        is_duplicate = True
                        break
                    else:
                        unique_tracks.remove(u)
                        break
            if not is_duplicate:
                unique_tracks.append(t)

        for t in unique_tracks:
            x, y, yaw = t.x[0], t.x[1], t.x[3]
            size = t.size
            score = t.confidence
            results.append({
                "id":         t.id,
                "x":          x,
                "y":          y,
                "yaw":        yaw,
                "size":       size,
                "confidence": score,
                "type":       t.current_class,
                "velocity":   t.pose_state[2:4].tolist(),
                "position":   [x, y, t.bboxes[-1].global_xyz[2] if t.bboxes else 0.0]
            })

        return results 

    

class MCTrackTrackerNode:
    LABEL_STR_TO_ID = {
        "car": 1,
        "truck": 2,
        "bus": 3,
        "trailer": 4,
        "constructionvehicle": 5,
        "pedestrian": 6,
        "motorcycle": 7,
        "bicycle": 8,
        "barrier": 9,
        "trafficcone": 10,
    }
    def __init__(self):
        # 1) ë°˜ë“œì‹œ init_node ë¶€í„° í˜¸ì¶œ
        rospy.init_node("mctrack_tracker_node", anonymous=True)

        # === [A] íƒ€ì´ë¨¸ë“¤ ì´ˆê¸°í™” ===
        self.tracking_timer = rospy.Timer(rospy.Duration(0.05), self.tracking_publish_callback)  # ê¸°ì¡´ í¼ë¸”ë¦¬ì‹œ ë£¨í”„
        self.marker_timer   = rospy.Timer(rospy.Duration(0.05), self.visualization_timer_callback)  # RViz ë§ˆì»¤ìš© ë£¨í”„
        # self.predict_timer  = rospy.Timer(rospy.Duration(0.1), self.tracker_loop)  # âœ… íŠ¸ë˜ì»¤ ì˜ˆì¸¡ ë£¨í”„ (10Hz)

        self.last_predict_time = None  # âœ… íŠ¸ë˜ì»¤ ë£¨í”„ìš© ì‹œê°„ ë³€ìˆ˜

        self.is_fusion_mode = True

        self.frame_idx       = 0
        self.start_time      = rospy.Time.now()
        self.marker_array    = MarkerArray()
        self.prev_track_ids  = set()

        # 4) Kalman íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
        self.tracker = KalmanMultiObjectTracker(
            use_precise_gdiou=False  # âœ… ì—¬ê¸°ì„œ í† ê¸€
        )

        # 5) í¼ë¸”ë¦¬ì…” ìƒì„± & êµ¬ë…ì ì—°ê²° ëŒ€ê¸°
        self.tracking_pub = rospy.Publisher("/tracking/objects",
                                            PfGMFATrackArray,
                                            queue_size=1)
        self.vis_pub = rospy.Publisher("/tracking/markers", MarkerArray, queue_size=1)

        # 6) ë¦¬í”Œë ˆì´ì–´ ì½œë°± êµ¬ë…
        self.detection_sub = rospy.Subscriber("/detection_objects",
                                            DetectionObjects,
                                            self.detection_callback,
                                            queue_size=1,
                                            tcp_nodelay=True)
        self.chassis_sub = rospy.Subscriber("/chassis",
                                            Chassis,
                                            self.chassis_callback,
                                            queue_size=1)

        self.chassis_buffer = deque(maxlen=100)

        # 7) Ego ìƒíƒœ ë³€ìˆ˜
        self.ego_vel         = 0.0
        self.ego_yaw_rate    = 0.0
        self.ego_yaw         = 0.0
        self.last_time_stamp = None

        self.predict_timer = rospy.Timer(rospy.Duration(0.05), self.tracker_loop)  # 20Hz ë£¨í”„ ì¶”ê°€
        
        # âœ… [ì—¬ê¸°] === ë§ˆì§€ë§‰ì— ê°™ì´ ë„£ì–´ì£¼ì„¸ìš” ===
        self.last_predict_stamp = None
        self.last_detection_stamp = None

        rospy.loginfo("MCTrackTrackerNode ì´ˆê¸°í™” ì™„ë£Œ.")

    def chassis_callback(self, msg):
        stamp_sec = msg.header.stamp.to_sec()  
        self.chassis_buffer.append((stamp_sec, msg))
    
    def get_nearest_chassis(self, target_stamp):
        if not self.chassis_buffer:
            return None
        times = [abs(t - target_stamp) for (t, _) in self.chassis_buffer]
        nearest_idx = int(np.argmin(times))
        return self.chassis_buffer[nearest_idx][1]

    def get_chassis_samples_in_range(self, t0: float, t1: float):
        return [
            msg for (ts, msg) in self.chassis_buffer
            if t0 <= ts <= t1
        ]    

    def integrate_ego_motion(self, samples, t0, t1, initial_yaw):
        dx_total, dy_total, dyaw_total = 0.0, 0.0, 0.0
        last_time = t0
        yaw = initial_yaw  # âœ… ì°¨ëŸ‰ í˜„ì¬ yaw(rad)ë¡œ ì´ˆê¸°í™”!

        rear_axle_offset = 1.0  # âœ… ì°¨ëŸ‰ë§ˆë‹¤ ë§ê²Œ ì„¤ì •

        for msg in samples:
            curr_time = msg.header.stamp.to_sec()
            dt = curr_time - last_time
            if dt <= 0:
                continue

            avg_speed_kph = (msg.whl_spd_fl + msg.whl_spd_fr + msg.whl_spd_rl + msg.whl_spd_rr) / 4.0
            vel = avg_speed_kph / 3.6
            yaw_rate = msg.cr_yrs_yr * np.pi / 180.0  # deg/s â†’ rad/s

            v_center = vel + yaw_rate * rear_axle_offset  # âœ… ì°¨ëŸ‰ ì¤‘ì‹¬ìœ¼ë¡œ ë³´ì •

            dx = v_center * dt * np.cos(yaw)
            dy = v_center * dt * np.sin(yaw)
            dyaw = yaw_rate * dt

            dx_total += dx
            dy_total += dy
            dyaw_total += dyaw
            yaw += dyaw  # âœ… íšŒì „ ëˆ„ì 

            last_time = curr_time

            rospy.loginfo(f"[EgoCompInt] dt={dt:.3f}s yaw={np.degrees(yaw):.1f}Â° "
                        f"dx={dx:.3f}, dy={dy:.3f}, dyaw={dyaw:.3f} rad")

        return dx_total, dy_total, dyaw_total
    

    def visualization_timer_callback(self, event):
        # 10Hz ì£¼ê¸°ë¡œ ë§ˆì»¤ í¼ë¸”ë¦¬ì‹œë§Œ ë‹´ë‹¹
        if hasattr(self, "marker_array"):
            self.vis_pub.publish(self.marker_array)

    def tracking_publish_callback(self, event):
        if not hasattr(self, 'last_time_stamp'):
            return  # ì•„ì§ ì²« detectionì´ ì•ˆ ë“¤ì–´ì™”ìœ¼ë©´ skip

        tracks = self.tracker.get_tracks()

        ta = PfGMFATrackArray()
        ta.header.stamp = self.last_detection_stamp
        ta.header.frame_id = "vehicle"

        for t in tracks:
            m = PfGMFATrack()
            m.pos_x = t["x"]
            m.pos_y = t["y"]
            m.yaw   = t["yaw"]
            dims    = list(t["size"])[:3]
            m.boundingbox = dims + [0.0] * 5
            m.confidence_ind = t["confidence"]
            m.id = int(t["id"])
            m.obj_class = t["type"]
            ta.tracks.append(m)

        self.tracking_pub.publish(ta)

    def tracker_loop(self, event):
        if self.last_predict_stamp is None or self.last_detection_stamp is None:
            return  # ì•„ì§ detectionì´ ì•ˆ ë“¤ì–´ì˜¤ë©´ skip

        dt = (self.last_detection_stamp - self.last_predict_stamp).to_sec()
        if dt <= 0:
            return

        self.tracker.predict(dt)
        self.last_predict_stamp = self.last_detection_stamp


    def delete_all_markers(self):
        for i, marker in reversed(list(enumerate(self.marker_array.markers))):
            if marker.action == Marker.DELETE:
                del self.marker_array.markers[i]
            else:
                marker.action = Marker.DELETE
        self.vis_pub.publish(self.marker_array)
        self.marker_array = MarkerArray()  


    def detection_callback(self, msg):
        try:
            # [1] íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚° ë° ìì°¨ ìƒíƒœ ì¶”ì •
            timestamp_sec = msg.header.stamp.to_sec()

            # âœ… ìµœì´ˆ ì´ˆê¸°í™”: predict íƒ€ì´ë¨¸ê°€ ì“¸ ìˆ˜ ìˆê²Œ!
            if self.last_predict_stamp is None:
                self.last_predict_stamp = msg.header.stamp

            # âœ… ë§¤ detectionë§ˆë‹¤ ìµœì‹ ìœ¼ë¡œ ê°±ì‹ !
            self.last_detection_stamp = msg.header.stamp

            # âœ… ìì°¨ ìƒíƒœ ì¶”ì • (ì†ë„ + ìš”ë ˆì´íŠ¸)
            nearest_chassis_msg = self.get_nearest_chassis(timestamp_sec)
            if nearest_chassis_msg:
                avg_speed_kph = (
                    nearest_chassis_msg.whl_spd_fl + nearest_chassis_msg.whl_spd_fr +
                    nearest_chassis_msg.whl_spd_rl + nearest_chassis_msg.whl_spd_rr
                ) / 4.0
                self.ego_vel = avg_speed_kph / 3.6
                self.ego_yaw_rate = nearest_chassis_msg.cr_yrs_yr * np.pi / 180.0

            # [2] ì‹œê°„ ê°„ê²© ê³„ì‚° (dt)
            if self.last_time_stamp is None:
                dt = 0.0
            else:
                dt = (msg.header.stamp - self.last_time_stamp).to_sec()
            self.last_time_stamp = msg.header.stamp

            self.frame_idx += 1
            # rospy.loginfo(f"[Tracker] Frame {self.frame_idx} (dt={dt:.3f}s)")

            # [3] ë™ì¼ íƒ€ì„ìŠ¤íƒ¬í”„ ì¤‘ë³µ ìˆ˜ì‹  ë°©ì§€
            if hasattr(self, "last_timestamp_sec") and abs(timestamp_sec - self.last_timestamp_sec) < 1e-6:
                rospy.logwarn(f"[WARN] ë™ì¼í•œ timestampê°€ ë°˜ë³µ ìˆ˜ì‹ ë¨: {timestamp_sec:.6f}")
            self.last_timestamp_sec = timestamp_sec

            # [4] Detection ë©”ì‹œì§€ â†’ ë‚´ë¶€ dict í¬ë§·ìœ¼ë¡œ ë³€í™˜ + í•„í„°ë§
            VALID_CLASSES = set(CLASS_CONFIG.keys())
            if self.is_fusion_mode:
                self.class_min_confidence = {
                    1: 0.03,   # car
                    2: 0.03,   # truck
                    3: 0.03,   # bus
                    4: 0.03,   # trailer
                    5: 0.02,   # construction vehicle
                    6: 0.08,   # pedestrian 
                    7: 0.02,   # motorcycle
                    8: 0.02,   # bicycle
                    9: 0.02,   # barrier
                    10: 0.01   # traffic cone 
                }# BEVFusion
            else:
                self.class_min_confidence = {
                    1: 0.14,  # Car
                    2: 0.08,  # Truck
                    3: 0.08,  # Bus
                    4: 0.08,  # Trailer
                    5: 0.12,  # ConstructionVehicle
                    6: 0.02,  # Pedestrian
                    7: 0.1,  # Motorcycle 
                    8: 0.02,  # Bicycle
                    9: 0.15,  # Barrier
                    10: 0.02, # TrafficCone
                } # LiDAR-only  
            detections = []
            for i, obj in enumerate(msg.objects):
                label_str = obj.label.strip().lower()
                label = self.LABEL_STR_TO_ID.get(label_str, -1)
                if label not in VALID_CLASSES:
                    continue
                if obj.score < self.class_min_confidence.get(label, 0.0):
                    continue
                detections.append({
                    "id":         i,
                    "position":   [obj.x, obj.y, obj.z],
                    "yaw":        obj.yaw,
                    "size":       [obj.l, obj.w, obj.h],
                    "type":       label,
                    "velocity":   [obj.vx, obj.vy],
                    "confidence": obj.score
                })

            # [5] Ego-motion ë³´ìƒë§Œ ìˆ˜í–‰ (predictëŠ” ë³„ë„ ë£¨í”„ì—ì„œ ì²˜ë¦¬ë¨)
            if dt > 0:
                t1 = timestamp_sec
                t0 = t1 - dt
                samples = self.get_chassis_samples_in_range(t0, t1)

                if samples:
                    # âœ… chassis ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì ë¶„ ë°©ì‹ ë³´ìƒ ì ìš©
                    dx, dy, dyaw = self.integrate_ego_motion(samples, t0, t1, self.ego_yaw)
                    self.tracker.apply_ego_compensation_to_all(dx, dy, dyaw)
                else:
                    # âœ… chassis ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë³´ìƒ ìƒëµ (ì¶”ë¡  ì™œê³¡ ë°©ì§€)
                    rospy.logwarn("[EgoComp] No chassis samples available â€” skipping ego-motion compensation")
            else:
                rospy.logwarn(f"Skipping ego compensation for dt={dt:.3f}s")

            # [6] íŠ¸ë˜ì»¤ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰ (ì˜ˆì¸¡ì€ íƒ€ì´ë¨¸ ë£¨í”„ì—ì„œ ìˆ˜í–‰ë¨)
            self.tracker.update(detections, dt)

            # [7] ì¶”ì  ê²°ê³¼ë¥¼ ë³€í™˜í•˜ì—¬ ë©”ì‹œì§€ë¡œ êµ¬ì„±
            tracks = self.tracker.get_tracks()
            # rospy.loginfo(f"[Tracker] Published Tracks: {len(tracks)}")

            ta = PfGMFATrackArray(header=msg.header)
            for t in tracks:
                m = PfGMFATrack()
                m.pos_x = t["x"]
                m.pos_y = t["y"]
                m.yaw   = t["yaw"]
                m.boundingbox = list(t["size"])[:3] + [0.0] * 5
                m.confidence_ind = t["confidence"]
                m.id = int(t["id"])
                m.obj_class = t["type"]
                ta.tracks.append(m)

            # [8] RViz ë§ˆì»¤ êµ¬ì„± ë° ì‚­ì œ/ê°±ì‹  ì²˜ë¦¬
            vis_header = Header(frame_id="vehicle", stamp=msg.header.stamp)
            current_ids = set(t["id"] for t in tracks)
            deleted_ids = getattr(self, "prev_track_ids", set()) - current_ids
            self.marker_array = MarkerArray()

            for tid in deleted_ids:
                for ns, base_id in [("track_meshes", 0), ("track_ids", 1000), ("track_arrows", 2000)]:
                    m = Marker()
                    m.header = vis_header
                    m.ns = ns
                    m.id = base_id + tid
                    m.action = Marker.DELETE
                    self.marker_array.markers.append(m)

            for t in tracks:
                m1 = create_single_track_marker(t, vis_header, t["id"])
                self.marker_array.markers.append(m1)

                m2 = create_text_marker(t, vis_header, 1000 + t["id"])
                if m2 is not None:
                    self.marker_array.markers.append(m2)

                m3 = create_arrow_marker(t, vis_header, 2000 + t["id"])
                self.marker_array.markers.append(m3)

            ego_marker = create_ego_marker(vis_header.stamp)
            self.marker_array.markers.append(ego_marker)

            self.vis_pub.publish(self.marker_array)
            self.prev_track_ids = current_ids

        except Exception as e:
            rospy.logerr(f"[detection_callback] Unexpected error: {e}\n{traceback.format_exc()}")

if __name__ == '__main__':
    # open("/tmp/mctrack_cost_debug.txt", "w").close() 
    try:
        MCTrackTrackerNode()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass 